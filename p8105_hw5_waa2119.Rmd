---
title: "p8105_hw5_waa2119"
author: "William Anderson"
date: "2022-11-07"
output: html_document
---


```{r, message = FALSE, warning = FALSE}

library(tidyverse)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 2

First we read in the homicide data from the Washington Post

```{r}
homicide_data = 
  read_csv("homicide/homicide-data.csv", na = "") %>%
  
  janitor::clean_names()
 

head(homicide_data, 10)
```

This data comprises 52,000 homicides in 50 large U.S. cities over the past decade. Using public records, the Washington Post acquired information about a decade of homicides including victim names, race, sex, age, location, and whether an arrest had been made. 

The size of the dataset is `r dim(homicide_data)`

The columns included are `r colnames(homicide_data)`

Now we will create a city_state variable (e.g. “Baltimore, MD”) and then summarize within cities to obtain the total number of homicides and the number of unsolved homicides (those for which the disposition is “Closed without arrest” or “Open/No arrest”).

```{r}
homicide_data_tidy = 
  
  homicide_data %>%
  
   mutate(city_state = str_c(city, ", ", state)) %>%
  
  mutate(unsolved = ifelse(disposition == "Closed without arrest" | disposition == "Open/No arrest", 1, 0)) %>%
  
  group_by(city_state) %>%
  
  summarize(total_homicides = n(), total_unsolved = sum(unsolved))

head(homicide_data_tidy, 25)
```

Now for the city of Baltimore, MD, we will use the prop.test function to estimate the proportion of homicides that are unsolved and analyze the estimated proportion and confidence intervals from the resulting tidy dataframe.


```{r}
homicide_baltimore = 
  
  homicide_data_tidy %>%
  
  filter(city_state %in% "Baltimore, MD") %>%
  
  mutate(
    prop_test = list(broom::tidy(prop.test(total_unsolved, total_homicides)))) %>%
  
  unnest(prop_test) %>%
  
  view

```


Now we will run prop.test for each of the cities and extract both the proportion of unsolved homicides and the confidence interval for each.

output = map(city_state, prop.test)
output = map2(.x = input_1, .y = input_2, ~func(arg_1 = .x, arg_2 = .y))

```{r}
prop_tests_homicides = 
  
   homicide_data_tidy %>%
  
  mutate(prop_test = map2(.x = total_unsolved, .y = total_homicides, ~prop.test(x = .x, n = .y))) %>%
  mutate(prop_test_broom = map(prop_test, broom::tidy)) %>%
  unnest(prop_test_broom) %>%
  select(city_state, total_unsolved, total_homicides, estimate, conf.low, conf.high) %>%
  view
```

Create a plot that shows the estimates and CIs for each city – check out geom_errorbar for a way to add error bars based on the upper and lower limits. Organize cities according to the proportion of unsolved homicides.

```{r}
  prop_tests_homicides =
  prop_tests_homicides %>%
    filter(!city_state %in% "Tulsa, AL")

  ggplot(prop_tests_homicides, aes(x = reorder(city_state, estimate), y = estimate, color = city_state)) + 
    
    geom_point() + 
    
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) +
    
    labs(title = "Unsolved Homicide Proportions in US Cities", 
         x = "", 
         y = "Proportion", 
         color = "Location") + 
    
    theme(legend.position = "right") +
    
  scale_x_discrete(guide = guide_axis(check.overlap = TRUE))
```


## Problem 3